{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of numeric features are: 7\n",
      "number of categorical features are: 4\n",
      "number of Discreate features are: 2\n",
      "number of Continous features are: 5\n",
      "120\n",
      "Linear Regression\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 553855.6665\n",
      "Mean Absolute Error 268101.6071\n",
      "r2_score 0.6218\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 502543.5930\n",
      "Mean Absolute Error 279618.5794\n",
      "r2_score 0.6645\n",
      "==============================\n",
      "Decision Tree Regressor\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 20797.2352\n",
      "Mean Absolute Error 5164.8199\n",
      "r2_score 0.9995\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 304571.9567\n",
      "Mean Absolute Error 125817.2965\n",
      "r2_score 0.8768\n",
      "==============================\n",
      "Random Forest Regressor\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 139406.2256\n",
      "Mean Absolute Error 40178.8654\n",
      "r2_score 0.9760\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 227373.1359\n",
      "Mean Absolute Error 102292.6491\n",
      "r2_score 0.9313\n",
      "==============================\n",
      "K-Nearest-Regressor\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 325873.4263\n",
      "Mean Absolute Error 91426.3628\n",
      "r2_score 0.8691\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 253024.3951\n",
      "Mean Absolute Error 112526.3461\n",
      "r2_score 0.9150\n",
      "==============================\n",
      "Lasso\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 553855.6710\n",
      "Mean Absolute Error 268099.2219\n",
      "r2_score 0.6218\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 502542.6698\n",
      "Mean Absolute Error 279614.7453\n",
      "r2_score 0.6645\n",
      "==============================\n",
      "Ridge\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 553856.3160\n",
      "Mean Absolute Error 268059.8015\n",
      "r2_score 0.6218\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 502533.8230\n",
      "Mean Absolute Error 279557.2169\n",
      "r2_score 0.6645\n",
      "==============================\n",
      "AdaboostRegressor\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 382430.4908\n",
      "Mean Absolute Error 256186.2395\n",
      "r2_score 0.8197\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 417388.6981\n",
      "Mean Absolute Error 272750.4724\n",
      "r2_score 0.7686\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df=pd.read_csv(\"cardekho_imputed.csv\")\n",
    "df.head()\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True,axis=1)\n",
    "df.head()\n",
    "#Data Cleaning\n",
    "df.isnull().sum()\n",
    "#Remmove unnessary columns \n",
    "df.drop(columns=[\"car_name\",\"brand\"],axis=1,inplace=True)\n",
    "df.head()\n",
    "len(df[\"model\"].unique())\n",
    "#Getting all different Types of  features \n",
    "num_features=[feature for feature in df.columns if df[feature].dtype!=\"O\"]\n",
    "print(f\"number of numeric features are: {len(num_features)}\")\n",
    "cat_features=[feature for feature in df.columns if df[feature].dtype==\"O\"]\n",
    "print(f\"number of categorical features are: {len(cat_features)}\")\n",
    "#If a Column contains categories less than or equal to 25 than it is said to be discreate feature\n",
    "discreate_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print(f\"number of Discreate features are: {len(discreate_features)}\")\n",
    "continous_features=[feature for feature in num_features if len(df[feature].unique())>25]\n",
    "print(f\"number of Continous features are: {len(continous_features)}\")\n",
    "#Splitting Dataset into Dependent and independent Featurees\n",
    "X=df.drop(\"selling_price\",axis=1)\n",
    "y=df[\"selling_price\"]\n",
    "X.head()\n",
    "df[\"model\"].value_counts()\n",
    "print(len(df[\"model\"].value_counts()))\n",
    "len(df[\"model\"].unique())\n",
    "#Applying label Encoding to the Model features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "X[\"model\"]=le.fit_transform(X[\"model\"])\n",
    "X.head()\n",
    "#only 3 categories \n",
    "X[\"seller_type\"].unique()\n",
    "X[\"fuel_type\"].unique()\n",
    "X[\"transmission_type\"].unique()\n",
    "#These above three features have very less categories so we can apply OneHotEncoding to these three\n",
    "num_features=X.select_dtypes(exclude=\"object\").columns \n",
    "one_hot_features=['seller_type','fuel_type','transmission_type']\n",
    "#Create a column transfoemer with three types of Transformers\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "numeric_transformer=StandardScaler()\n",
    "Oh_transformers=OneHotEncoder(drop=\"first\")\n",
    "preprocessor=ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric_transformer\",numeric_transformer,num_features),\n",
    "        (\"oh_transformer\",Oh_transformers,one_hot_features)\n",
    "        ],remainder=\"passthrough\"\n",
    ")\n",
    "X=preprocessor.fit_transform(X)\n",
    "import sys\n",
    "import numpy as np \n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pd.DataFrame(X)\n",
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)\n",
    "#MODEL TRAINING\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "\n",
    "#Creating a function to evaluate Model\n",
    "import math\n",
    "def evaluate_model(true,predicted):\n",
    "    mae=mean_absolute_error(true,predicted)\n",
    "    mse=mean_squared_error(true,predicted)\n",
    "    rmse=math.sqrt(mse)\n",
    "    r2score=r2_score(true,predicted)\n",
    "    return mae,rmse,r2score \n",
    "#Beggining the Model Training\n",
    "models={\n",
    "    \"Linear Regression\":LinearRegression(),\n",
    "    \"Decision Tree Regressor\":DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\":RandomForestRegressor(),\n",
    "    \"K-Nearest-Regressor\":KNeighborsRegressor(),\n",
    "    \"Lasso\":Lasso(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"AdaboostRegressor\":AdaBoostRegressor()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #make Predictions\n",
    "    y_train_pred=model.predict(X_train)\n",
    "    y_test_pred=model.predict(X_test)\n",
    "\n",
    "    #Evaluate train and test Datasets\n",
    "    model_train_mae,model_train_rmse,model_train_r2=evaluate_model(y_train,y_train_pred)\n",
    "\n",
    "    model_test_mae,model_test_rmse,model_test_r2=evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model Perfomance For Training Set \")\n",
    "    print(\"Root mean Squared Error {:.4f}\".format(model_train_rmse))\n",
    "    print(\"Mean Absolute Error {:.4f}\".format(model_train_mae))\n",
    "    print(\"r2_score {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    print(\"Model Perfomance For Testing Set \")\n",
    "    print(\"Root mean Squared Error {:.4f}\".format(model_test_rmse))\n",
    "    print(\"Mean Absolute Error {:.4f}\".format(model_test_mae))\n",
    "    print(\"r2_score {:.4f}\".format(model_test_r2))\n",
    "\n",
    "    print(\"=\"*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params={\n",
    "    \"n_estimators\":[50,60,70,80],\n",
    "    \"loss\":[\"linear\",\"square\",\"exponential\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models=[\n",
    "    (\"ADABoost\",AdaBoostRegressor(),ada_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "-----Best Params for ADABoost----------\n",
      "{'n_estimators': 70, 'loss': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning using Randomized Cv\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model_param={}\n",
    "for name,model,params in randomcv_models:\n",
    "    random=RandomizedSearchCV(estimator=model,param_distributions=params,n_iter=100,cv=3,verbose=2,n_jobs=-1)\n",
    "    random.fit(X_train,y_train)\n",
    "    model_param[name]=random.best_params_\n",
    "\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"-----Best Params for {model_name}----------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost\n",
      "Model Perfomance For Training Set \n",
      "Root mean Squared Error 478302.6068\n",
      "Mean Absolute Error 379278.0082\n",
      "r2_score 0.7179\n",
      "--------------------------------------\n",
      "Model Perfomance For Testing Set \n",
      "Root mean Squared Error 506892.5932\n",
      "Mean Absolute Error 394770.0377\n",
      "r2_score 0.6587\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "#Beggining the Model Training\n",
    "models={\n",
    "    \"Adaboost\":AdaBoostRegressor(n_estimators=70,loss=\"linear\")\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #make Predictions\n",
    "    y_train_pred=model.predict(X_train)\n",
    "    y_test_pred=model.predict(X_test)\n",
    "\n",
    "    #Evaluate train and test Datasets\n",
    "    model_train_mae,model_train_rmse,model_train_r2=evaluate_model(y_train,y_train_pred)\n",
    "\n",
    "    model_test_mae,model_test_rmse,model_test_r2=evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print(\"Model Perfomance For Training Set \")\n",
    "    print(\"Root mean Squared Error {:.4f}\".format(model_train_rmse))\n",
    "    print(\"Mean Absolute Error {:.4f}\".format(model_train_mae))\n",
    "    print(\"r2_score {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    print(\"Model Perfomance For Testing Set \")\n",
    "    print(\"Root mean Squared Error {:.4f}\".format(model_test_rmse))\n",
    "    print(\"Mean Absolute Error {:.4f}\".format(model_test_mae))\n",
    "    print(\"r2_score {:.4f}\".format(model_test_r2))\n",
    "\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
