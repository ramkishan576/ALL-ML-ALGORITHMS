{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 4.62357 % missing values \n",
      "TypeofContact 0.51146 % missing values \n",
      "DurationOfPitch 5.13502 % missing values \n",
      "NumberOfFollowups 0.92062 % missing values \n",
      "PreferredPropertyStar 0.53191 % missing values \n",
      "NumberOfTrips 2.86416 % missing values \n",
      "NumberOfChildrenVisiting 1.35025 % missing values \n",
      "MonthlyIncome 4.76678 % missing values \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4888 entries, 0 to 4887\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   ProdTaken               4888 non-null   int64  \n",
      " 1   Age                     4888 non-null   float64\n",
      " 2   TypeofContact           4888 non-null   object \n",
      " 3   CityTier                4888 non-null   int64  \n",
      " 4   DurationOfPitch         4888 non-null   float64\n",
      " 5   Occupation              4888 non-null   object \n",
      " 6   Gender                  4888 non-null   object \n",
      " 7   NumberOfFollowups       4888 non-null   float64\n",
      " 8   ProductPitched          4888 non-null   object \n",
      " 9   PreferredPropertyStar   4888 non-null   float64\n",
      " 10  MaritalStatus           4888 non-null   object \n",
      " 11  NumberOfTrips           4888 non-null   float64\n",
      " 12  Passport                4888 non-null   int64  \n",
      " 13  PitchSatisfactionScore  4888 non-null   int64  \n",
      " 14  OwnCar                  4888 non-null   int64  \n",
      " 15  Designation             4888 non-null   object \n",
      " 16  MonthlyIncome           4888 non-null   float64\n",
      " 17  totalVisitings          4888 non-null   float64\n",
      "dtypes: float64(7), int64(5), object(6)\n",
      "memory usage: 687.5+ KB\n",
      "Number of Numerical features:12\n",
      "Number of Categorical features are:6\n",
      "Number of discreate features are:9\n",
      "Number of Continous features are:3\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4888 entries, 0 to 4887\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Age                     4888 non-null   float64\n",
      " 1   TypeofContact           4888 non-null   object \n",
      " 2   CityTier                4888 non-null   int64  \n",
      " 3   DurationOfPitch         4888 non-null   float64\n",
      " 4   Occupation              4888 non-null   object \n",
      " 5   Gender                  4888 non-null   object \n",
      " 6   NumberOfFollowups       4888 non-null   float64\n",
      " 7   ProductPitched          4888 non-null   object \n",
      " 8   PreferredPropertyStar   4888 non-null   float64\n",
      " 9   MaritalStatus           4888 non-null   object \n",
      " 10  NumberOfTrips           4888 non-null   float64\n",
      " 11  Passport                4888 non-null   int64  \n",
      " 12  PitchSatisfactionScore  4888 non-null   int64  \n",
      " 13  OwnCar                  4888 non-null   int64  \n",
      " 14  Designation             4888 non-null   object \n",
      " 15  MonthlyIncome           4888 non-null   float64\n",
      " 16  totalVisitings          4888 non-null   float64\n",
      "dtypes: float64(7), int64(4), object(6)\n",
      "memory usage: 649.3+ KB\n",
      "Random forest\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:1.0000\n",
      "F1 Score:1.0000\n",
      "Precision:1.0000\n",
      "Recall:1.0000\n",
      "ROC AUC Score:1.0000\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.9254\n",
      "F1 Score:0.7712\n",
      "Precision:0.9609\n",
      "Recall:0.6440\n",
      "ROC AUC Score:0.8188\n",
      "Random forest\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:1.0000\n",
      "F1 Score:1.0000\n",
      "Precision:1.0000\n",
      "Recall:1.0000\n",
      "ROC AUC Score:1.0000\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.9243\n",
      "F1 Score:0.7658\n",
      "Precision:0.9680\n",
      "Recall:0.6335\n",
      "ROC AUC Score:0.8142\n",
      "================================================\n",
      "decision tree\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:1.0000\n",
      "F1 Score:1.0000\n",
      "Precision:1.0000\n",
      "Recall:1.0000\n",
      "ROC AUC Score:1.0000\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.9254\n",
      "F1 Score:0.8022\n",
      "Precision:0.8315\n",
      "Recall:0.7749\n",
      "ROC AUC Score:0.8684\n",
      "================================================\n",
      "logistic regression\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:0.8460\n",
      "F1 Score:0.4234\n",
      "Precision:0.7016\n",
      "Recall:0.3032\n",
      "ROC AUC Score:0.6368\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.8364\n",
      "F1 Score:0.4118\n",
      "Precision:0.6914\n",
      "Recall:0.2932\n",
      "ROC AUC Score:0.6307\n",
      "================================================\n",
      "Gradient Boosting\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:0.8939\n",
      "F1 Score:0.6382\n",
      "Precision:0.8756\n",
      "Recall:0.5021\n",
      "ROC AUC Score:0.7429\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.8589\n",
      "F1 Score:0.5208\n",
      "Precision:0.7732\n",
      "Recall:0.3927\n",
      "ROC AUC Score:0.6824\n",
      "================================================\n",
      "AdaBoost\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:0.8565\n",
      "F1 Score:0.4867\n",
      "Precision:0.7308\n",
      "Recall:0.3649\n",
      "ROC AUC Score:0.6670\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.8354\n",
      "F1 Score:0.4311\n",
      "Precision:0.6630\n",
      "Recall:0.3194\n",
      "ROC AUC Score:0.6400\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "df=pd.read_csv(\"Travel.csv\")\n",
    "df.head()\n",
    "#DATA CLEANING\n",
    "''' \n",
    "Handling Missing Values\n",
    "Handling Duplicates\n",
    "Checking Datatype\n",
    "Understand the Dataset\n",
    "'''\n",
    "df.isnull().sum()\n",
    "#Check all the categories\n",
    "df[\"Gender\"].value_counts()\n",
    "df[\"MaritalStatus\"].value_counts()\n",
    "#Replace fe male with Feamale\n",
    "df[\"Gender\"]=df[\"Gender\"].replace(\"Fe Male\",\"Female\")\n",
    "df[\"MaritalStatus\"]=df[\"MaritalStatus\"].replace(\"Single\",\"Unmarried\")\n",
    "df.head()\n",
    "df[\"Gender\"].value_counts()\n",
    "\n",
    "df[\"MaritalStatus\"].value_counts()\n",
    "#Checking the features with nan Values\n",
    "features_with_na=[features for features in df.columns if df[features].isnull().sum()>=1]\n",
    "features_with_na\n",
    "df[\"Age\"].isnull().sum()\n",
    "df[\"TypeofContact\"].isnull().sum()\n",
    "df[\"Age\"].isnull().mean()\n",
    "#checking what percentage of null values in each column\n",
    "for feature in features_with_na:\n",
    "    print(feature,np.round(df[feature].isnull().mean()*100,5),\"% missing values \")\n",
    "#Statistics on numerical columns (Null cols)\n",
    "#df[features_with_na].describe()\n",
    "df[features_with_na].select_dtypes(exclude='object').describe()\n",
    "#IMPUTUTING NULL VALUES\n",
    "# we use median and mmode imputation techniques to fill the null values\n",
    "features_with_na\n",
    "df[\"TypeofContact\"].mode()[0]\n",
    "#AGE median\n",
    "df[\"Age\"].fillna(df[\"Age\"].median(),inplace=True)\n",
    "\n",
    "#TYPE OF CONTRACT mode \n",
    "df[\"TypeofContact\"].fillna(df[\"TypeofContact\"].mode()[0],inplace=True)\n",
    "\n",
    "#DurationOfPitch median\n",
    "df[\"DurationOfPitch\"].fillna(df[\"DurationOfPitch\"].median(),inplace=True)\n",
    "\n",
    "#NumberOfFollowups mode \n",
    "df[\"NumberOfFollowups\"].fillna(df[\"NumberOfFollowups\"].mode()[0],inplace=True)\n",
    "\n",
    "#Preferred Property Star mode\n",
    "df[\"PreferredPropertyStar\"].fillna(df[\"PreferredPropertyStar\"].mode()[0],inplace=True)\n",
    "\n",
    "#Number of Trips median\n",
    "df[\"NumberOfTrips\"].fillna(df[\"NumberOfTrips\"].median(),inplace=True)\n",
    "\n",
    "#Number of childredn Visiting mode\n",
    "df[\"NumberOfChildrenVisiting\"].fillna(df[\"NumberOfChildrenVisiting\"].mode()[0],inplace=True)\n",
    "\n",
    "#monthly income median\n",
    "df[\"MonthlyIncome\"].fillna(df[\"MonthlyIncome\"].median(),inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "#HERE we can see completely filled the null values\n",
    "df.isnull().sum()\n",
    "#CustomerId is not important,so we are going to remove that feature\n",
    "df.drop('CustomerID',inplace=True,axis=1)\n",
    "#One column is deleted\n",
    "len(df.columns)\n",
    "#FEATURE ENGINEERING\n",
    "#Creating one new feature with total visiting by combining numberOfpersonsVisiting+numberOfChildrens Visiting\n",
    "df[\"totalVisitings\"]=df[\"NumberOfPersonVisiting\"]+df[\"NumberOfChildrenVisiting\"]\n",
    "df[\"totalVisitings\"]\n",
    "df.drop(columns=[\"NumberOfPersonVisiting\",'NumberOfChildrenVisiting'],inplace=True,axis=1)\n",
    "len(df.columns)\n",
    "df.head()\n",
    "df.info()\n",
    "#Get all the numeric Features\n",
    "num_features=[feature for feature in df.columns if df[feature].dtype!=\"O\"]\n",
    "print(f\"Number of Numerical features:{len(num_features)}\")\n",
    "#Get all categorical Features\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype==\"O\"]\n",
    "print(f\"Number of Categorical features are:{len(categorical_features)}\")\n",
    "#Discreate Features\n",
    "discreate_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print(f\"Number of discreate features are:{len(discreate_features)}\")\n",
    "#Continous features\n",
    "continous_features=[feature for feature in num_features if feature not in discreate_features]\n",
    "print(f\"Number of Continous features are:{len(continous_features)}\")\n",
    "#from numerical features we get both discreate and continous features\n",
    "#Train Test Split and Model Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df.drop([\"ProdTaken\"],axis=1)\n",
    "y=df[\"ProdTaken\"]\n",
    "X.head()\n",
    "y.head()\n",
    "y.value_counts()\n",
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape,X_test.shape\n",
    "X.info()\n",
    "#Create Column transformers with 3 types of Transformers\n",
    "cat_features=X.select_dtypes(include=\"object\").columns \n",
    "num_features=X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "numeric_transformer=StandardScaler()\n",
    "oh_transformer=OneHotEncoder(drop=\"first\")\n",
    "\n",
    "preprocessor=ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"oneHotEncoder\",oh_transformer,categorical_features),\n",
    "        (\"StandardScaler\",numeric_transformer,num_features)\n",
    "    ]\n",
    ")\n",
    "#For example(WHY drop=TRUE):\n",
    "\n",
    "#If a feature has three categories: A, B, and C, instead of creating three columns (A, B, C), the encoder will create two columns (B, C) and drop the first (A).\n",
    "#If the row corresponds to category A, both B and C columns will be 0.\n",
    "'''Without drop=\"first\" (one-hot encoding):\n",
    "The encoder creates one column for each category.\n",
    "\n",
    "Red\t  Green\tBlue\n",
    "1\t  0\t    0\n",
    "0\t  1\t    0\n",
    "0\t  0\t    1\n",
    "1\t  0\t    0\n",
    "With drop=\"first\":\n",
    "The encoder drops the first category (Red), leaving just two columns (Green and Blue).\n",
    "\n",
    "Green\tBlue\n",
    "0\t    0\n",
    "1\t    0\n",
    "0\t    1\n",
    "0\t    0\n",
    "By dropping the first column, \n",
    "the information about the first category (Red) \n",
    "is still retainedâ€”when both Green and Blue are 0, \n",
    "the category must be Red. This helps reduce the number \n",
    "of columns and avoids redundancy.\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preprocessor\n",
    "#AApplying transformation on training dataset\n",
    "#Here we can see one hot encoding on categorical fetures and standara scaling in all numerical features(to scale down the values)\n",
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_train\n",
    "pd.DataFrame(X_train)\n",
    "#applying transformation on test data(transform)\n",
    "X_test=preprocessor.transform(X_test)\n",
    "X_test\n",
    "#Random Forest Classifier Training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,roc_auc_score,roc_curve\n",
    "#Efficient way of training the model\n",
    "models={\n",
    "    \"Random forest\":RandomForestClassifier()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train) #Model train\n",
    "\n",
    "\n",
    "    #Make Predictions    \n",
    "    y_train_pred=model.predict(X_train)\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    \n",
    "    #Training set Perfomance\n",
    "    train_accuracy=accuracy_score(y_train,y_train_pred)\n",
    "    train_f1score=f1_score(y_train,y_train_pred)\n",
    "    train_precision=precision_score(y_train,y_train_pred)\n",
    "    train_recall=recall_score(y_train,y_train_pred)\n",
    "    train_roc_auc_score=roc_auc_score(y_train,y_train_pred)\n",
    "\n",
    "\n",
    "    #Test set Perfomance\n",
    "    test_accuracy=accuracy_score(y_test,y_test_pred)\n",
    "    test_f1score=f1_score(y_test,y_test_pred)\n",
    "    test_precision=precision_score(y_test,y_test_pred)\n",
    "    test_recall=recall_score(y_test,y_test_pred)\n",
    "    test_roc_auc_score=roc_auc_score(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    print(\"**********\")\n",
    "    print(\"Model Perfomance for Training Set\")\n",
    "    print(\"Accuracy:{:.4f}\".format(train_accuracy))\n",
    "    print(\"F1 Score:{:.4f}\".format(train_f1score))\n",
    "    print(\"Precision:{:.4f}\".format(train_precision))\n",
    "    print(\"Recall:{:.4f}\".format(train_recall))\n",
    "    print(\"ROC AUC Score:{:.4f}\".format(train_roc_auc_score))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "    \n",
    "    \n",
    "    print(\"Model Perfomance for Test Set\")\n",
    "    print(\"Accuracy:{:.4f}\".format(test_accuracy))\n",
    "    print(\"F1 Score:{:.4f}\".format(test_f1score))\n",
    "    print(\"Precision:{:.4f}\".format(test_precision))\n",
    "    print(\"Recall:{:.4f}\".format(test_recall))\n",
    "    print(\"ROC AUC Score:{:.4f}\".format(test_roc_auc_score))\n",
    "\n",
    "\n",
    "#Here efficiently we can add many algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,ConfusionMatrixDisplay,precision_score,recall_score,f1_score,roc_auc_score,roc_curve\n",
    "models={\n",
    "    \"Random forest\":RandomForestClassifier(),\n",
    "    \"decision tree\":DecisionTreeClassifier(),\n",
    "    \"logistic regression\":LogisticRegression(),\n",
    "    \"Gradient Boosting\":GradientBoostingClassifier(),\n",
    "    \"AdaBoost\":AdaBoostClassifier(),\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train) #Model train\n",
    "\n",
    "\n",
    "    #Make Predictions    \n",
    "    y_train_pred=model.predict(X_train)\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    \n",
    "    #Training set Perfomance\n",
    "    train_accuracy=accuracy_score(y_train,y_train_pred)\n",
    "    train_f1score=f1_score(y_train,y_train_pred)\n",
    "    train_precision=precision_score(y_train,y_train_pred)\n",
    "    train_recall=recall_score(y_train,y_train_pred)\n",
    "    train_roc_auc_score=roc_auc_score(y_train,y_train_pred)\n",
    "\n",
    "\n",
    "    #Test set Perfomance\n",
    "    test_accuracy=accuracy_score(y_test,y_test_pred)\n",
    "    test_f1score=f1_score(y_test,y_test_pred)\n",
    "    test_precision=precision_score(y_test,y_test_pred)\n",
    "    test_recall=recall_score(y_test,y_test_pred)\n",
    "    test_roc_auc_score=roc_auc_score(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    print(\"**********\")\n",
    "    print(\"Model Perfomance for Training Set\")\n",
    "    print(\"Accuracy:{:.4f}\".format(train_accuracy))\n",
    "    print(\"F1 Score:{:.4f}\".format(train_f1score))\n",
    "    print(\"Precision:{:.4f}\".format(train_precision))\n",
    "    print(\"Recall:{:.4f}\".format(train_recall))\n",
    "    print(\"ROC AUC Score:{:.4f}\".format(train_roc_auc_score))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "    \n",
    "    \n",
    "    print(\"Model Perfomance for Test Set\")\n",
    "    print(\"Accuracy:{:.4f}\".format(test_accuracy))\n",
    "    print(\"F1 Score:{:.4f}\".format(test_f1score))\n",
    "    print(\"Precision:{:.4f}\".format(test_precision))\n",
    "    print(\"Recall:{:.4f}\".format(test_recall))\n",
    "    print(\"ROC AUC Score:{:.4f}\".format(test_roc_auc_score))\n",
    "    \n",
    "    print(\"================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [50, 60, 70, 80, 90], 'algorithm': ['SAMME', 'SAMME.R']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_params={\n",
    "    \"n_estimators\":[50,60,70,80,90],\n",
    "    \"algorithm\":[\"SAMME\",\"SAMME.R\"]\n",
    "}\n",
    "adaboost_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AB',\n",
       "  AdaBoostClassifier(),\n",
       "  {'n_estimators': [50, 60, 70, 80, 90], 'algorithm': ['SAMME', 'SAMME.R']})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomcv_model=[\n",
    "    (\"AB\",AdaBoostClassifier(),adaboost_params)\n",
    "]\n",
    "randomcv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "-----Best Params for AB--------\n",
      "{'n_estimators': 80, 'algorithm': 'SAMME'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model_param={}\n",
    "for name,model,params in randomcv_model:\n",
    "    random=RandomizedSearchCV(estimator=model,param_distributions=params,n_iter=100,cv=3,verbose=2,n_jobs=-1)\n",
    "\n",
    "    random.fit(X_train,y_train)\n",
    "    model_param[name]=random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"-----Best Params for {model_name}--------\")\n",
    "    print(model_param[model_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:1.0000\n",
      "F1 Score:1.0000\n",
      "Precision:1.0000\n",
      "Recall:1.0000\n",
      "ROC AUC Score:1.0000\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.9294\n",
      "F1 Score:0.7864\n",
      "Precision:0.9621\n",
      "Recall:0.6649\n",
      "ROC AUC Score:0.8293\n",
      "================================================\n",
      "adaboost\n",
      "**********\n",
      "Model Perfomance for Training Set\n",
      "Accuracy:0.8465\n",
      "F1 Score:0.3802\n",
      "Precision:0.7699\n",
      "Recall:0.2524\n",
      "ROC AUC Score:0.6176\n",
      "----------------------------------------\n",
      "Model Perfomance for Test Set\n",
      "Accuracy:0.8364\n",
      "F1 Score:0.3496\n",
      "Precision:0.7818\n",
      "Recall:0.2251\n",
      "ROC AUC Score:0.6049\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Random forest\":RandomForestClassifier(n_estimators=1000,min_samples_split= 2,max_features= 8, max_depth=None),\n",
    "    \"adaboost\":AdaBoostClassifier(n_estimators=80,algorithm=\"SAMME\")\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train) #Model train\n",
    "\n",
    "\n",
    "    #Make Predictions    \n",
    "    y_train_pred=model.predict(X_train)\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    \n",
    "    #Training set Perfomance\n",
    "    train_accuracy=accuracy_score(y_train,y_train_pred)\n",
    "    train_f1score=f1_score(y_train,y_train_pred)\n",
    "    train_precision=precision_score(y_train,y_train_pred)\n",
    "    train_recall=recall_score(y_train,y_train_pred)\n",
    "    train_roc_auc_score=roc_auc_score(y_train,y_train_pred)\n",
    "\n",
    "\n",
    "    #Test set Perfomance\n",
    "    test_accuracy=accuracy_score(y_test,y_test_pred)\n",
    "    test_f1score=f1_score(y_test,y_test_pred)\n",
    "    test_precision=precision_score(y_test,y_test_pred)\n",
    "    test_recall=recall_score(y_test,y_test_pred)\n",
    "    test_roc_auc_score=roc_auc_score(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    print(\"**********\")\n",
    "    print(\"Model Perfomance for Training Set\")\n",
    "    print(\"Accuracy:{:.4f}\".format(train_accuracy))\n",
    "    print(\"F1 Score:{:.4f}\".format(train_f1score))\n",
    "    print(\"Precision:{:.4f}\".format(train_precision))\n",
    "    print(\"Recall:{:.4f}\".format(train_recall))\n",
    "    print(\"ROC AUC Score:{:.4f}\".format(train_roc_auc_score))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "    \n",
    "    \n",
    "    print(\"Model Perfomance for Test Set\")\n",
    "    print(\"Accuracy:{:.4f}\".format(test_accuracy))\n",
    "    print(\"F1 Score:{:.4f}\".format(test_f1score))\n",
    "    print(\"Precision:{:.4f}\".format(test_precision))\n",
    "    print(\"Recall:{:.4f}\".format(test_recall))\n",
    "    print(\"ROC AUC Score:{:.4f}\".format(test_roc_auc_score))\n",
    "    \n",
    "    print(\"================================================\")\n",
    "\n",
    "#Here we can see the increase in the recall compare to before\n",
    "#Plotting Roc AUC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
